## 全量参数微调与参数高效微调
微调主要分为全量参数微调与参数高效微调(PEFT-LoRA)

### 高效微调技术
粗略分为以下三大类

1. 增加额外参数（A）
2. 选取一部分参数更新（S）
3. 引入重参数化（R）
   - 类适配器（Adapter-like）方法
   - 软提示（Soft prompts）

参数高效微调技术有BitFit、Prefix Tuning、Prompt Tuning、P-Tuning、Adapter Tuning、LoRA

### reference
- [大模型参数高效微调技术原理综述](https://zhuanlan.zhihu.com/p/635152813)

---

### BitFit
是一种稀疏的微调方法，它训练时只更新bias的参数或者部分bias参数。

- attention模块中计算query,key,value的bias
- 合并多个attention结果时涉及到的bias
- MLP层中的bias
- Layernormalization层的bias参数


### Prefix Tuning
为LM添加可训练，任务特定的前缀，

在输入token之前构造一段任务相关的virtual tokens作为Prefix，然后训练的时候只更新Prefix部分的参数，而PLM中的其他部分参数固定

针对不同的模型结构，需要构造不同的Prefix。

#### example
```text
假设我们有一个预训练的 Transformer 模型（比如 GPT），我们希望用它来完成情感分类（判断一段文本的情感是正面还是负面）

我们有以下输入句子：
- 输入：`"这家餐厅的服务非常糟糕。"`
- 目标：判断这句话的情感是正面还是负面。
使用 Prefix Tuning 的过程如下：
1. 添加前缀：`[Prefix_1, Prefix_2, Prefix_3, "这家", "餐厅", "的", "服务", "非常", "糟糕", "。"]`
2. 前缀 `[Prefix_1, Prefix_2, Prefix_3]` 是一组可训练的向量，初始值可能是随机初始化或通过某种方式预设。
3. 将上述序列输入到 Transformer 模型中，模型根据前缀的信息调整其内部表示。
4. 输出：模型可能生成一个分类标签，例如“负面情感”。
```

```python
class PrefixTuning(nn.Module):
    def __init__(self, model, prefix_length, hidden_size):
        super(PrefixTuning, self).__init__()
        self.model = model
        self.prefix_length = prefix_length
        self.hidden_size = hidden_size
        # 创建可学习的前缀参数
        self.prefix_tokens = nn.Parameter(torch.randn(prefix_length, hidden_size))

    def forward(self, input_ids, attention_mask=None):
        batch_size = input_ids.size(0)
        # 扩展前缀参数以匹配批次大小
        prefix = self.prefix_tokens.unsqueeze(0).expand(batch_size, -1, -1)
        # 获取模型的嵌入层输出
        inputs_embeds = self.model.get_input_embeddings()(input_ids)
        # 将前缀与输入嵌入拼接
        inputs_embeds = torch.cat([prefix, inputs_embeds], dim=1)
        # 调整注意力掩码以包含前缀
        if attention_mask is not None:
            prefix_mask = torch.ones(batch_size, self.prefix_length).to(attention_mask.device)
            attention_mask = torch.cat([prefix_mask, attention_mask], dim=1)
        # 模型前向传播
        outputs = self.model(inputs_embeds=inputs_embeds, attention_mask=attention_mask)
        return outputs
```


### Prompt Tuning

可以看作是Prefix Tuning的简化版本，它给每个任务定义了自己的Prompt，然后拼接到数据上作为输入，但只在输入层加入prompt tokens，并且不需要加入 MLP 进行调整来解决难训练的问题。

- **传统微调方法**：我们会通过标注数据对整个模型进行微调。
- **Prompt Tuning 方法**：我们设计一个特定的提示模板，并通过调整提示中的“软提示”（soft prompts）来引导模型生成正确的输出

```text
1. 输入句子：`"这家餐厅的服务非常糟糕。"`
2. 提示模板：`"将以下句子分类为正面或负面情感：[输入句子] 情感是："`
3. 输出：`"负面"`
```
Prompt Tuning 的核心在于设计合适的提示模板，并通过学习“软提示”来优化模型的表现。


### reference
- [参数高效微调综述2](https://zhuanlan.zhihu.com/p/635686756)

---

### P-Tuning



### P-Tuning2



### reference
- [参数高效微调综述3](https://zhuanlan.zhihu.com/p/635848732)

---

### Adapter Tuning



### AdapterFusion


### AdapterDrop


### reference
- [参数高效微调综述4](https://zhuanlan.zhihu.com/p/636038478)

---

### LoRA



### AdaLoRA


### QLoRA

### reference
- [参数高效微调综述5](https://zhuanlan.zhihu.com/p/636215898)

---

### MAM Adapter



### UniPELT



### reference
- [参数高效微调综述6](https://zhuanlan.zhihu.com/p/636362246)

---

### 最佳实践、总结


### reference
- [参数高效微调综述7](https://zhuanlan.zhihu.com/p/649755252)
